{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_NER_BERT",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILw_I2b2ncak",
        "colab_type": "text"
      },
      "source": [
        "### NER with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjtvAHAsnf02",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "* https://medium.com/@yingbiao/ner-with-bert-in-action-936ff275bc73"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mYBNEpsmGIM",
        "colab_type": "code",
        "outputId": "6173a876-1b92-43d6-998e-1f389b0f3097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeE0EodSmMsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiUFaF97mdGq",
        "colab_type": "code",
        "outputId": "395a23b4-d143-4700-8d9e-ba4c62e9db5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_path = \"/content/drive/My Drive/Datahack NLP Workshop/GMB_NER/\"\n",
        "df = pd.read_csv(data_path + \"ner_dataset.csv\", encoding = \"ISO-8859-1\")\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1048575, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lp63aJjmfZ7",
        "colab_type": "code",
        "outputId": "1e219931-5ff2-44c5-dcb1-8f7e39881168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg2JGUz5nGf9",
        "colab_type": "code",
        "outputId": "dd9149df-588e-49e7-e566-167cf4b5f625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df[\"Sentence #\"].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47959"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J4u2nUNnNaH",
        "colab_type": "code",
        "outputId": "c422a3c2-5d73-4307-9bf3-2e4a37d5e67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df[\"Word\"].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zay3Gl6unPu9",
        "colab_type": "code",
        "outputId": "3a6613d8-9f4e-4178-8278-ab7e683a9d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "df[\"POS\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NNS', 'IN', 'VBP', 'VBN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'CC',\n",
              "       'JJ', '.', 'VBD', 'WP', '``', 'CD', 'PRP', 'VBZ', 'POS', 'VBG',\n",
              "       'RB', ',', 'WRB', 'PRP$', 'MD', 'WDT', 'JJR', ':', 'JJS', 'WP$',\n",
              "       'RP', 'PDT', 'NNPS', 'EX', 'RBS', 'LRB', 'RRB', '$', 'RBR', ';',\n",
              "       'UH', 'FW'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkn37JHknSkn",
        "colab_type": "code",
        "outputId": "0d8f3188-23b7-4059-9740-db951f2d1bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "df[\"Tag\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0_YNouunVVk",
        "colab_type": "code",
        "outputId": "baa2bef1-95af-47be-9ad0-5202324bc750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "df[\"Tag\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        887908\n",
              "B-geo     37644\n",
              "B-tim     20333\n",
              "B-org     20143\n",
              "I-per     17251\n",
              "B-per     16990\n",
              "I-org     16784\n",
              "B-gpe     15870\n",
              "I-geo      7414\n",
              "I-tim      6528\n",
              "B-art       402\n",
              "B-eve       308\n",
              "I-art       297\n",
              "I-eve       253\n",
              "B-nat       201\n",
              "I-gpe       198\n",
              "I-nat        51\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sp1pxbXoBfY",
        "colab_type": "text"
      },
      "source": [
        "### Parse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khlgNbAZnrbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "malKNT5goEEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(df)\n",
        "\n",
        "# Get sentence data\n",
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "\n",
        "# Get pos data\n",
        "poses = [[s[1] for s in sent] for sent in getter.sentences]\n",
        "\n",
        "# Get tag labels data\n",
        "labels = [[s[2] for s in sent] for sent in getter.sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKgfH8Y0og1P",
        "colab_type": "code",
        "outputId": "9ba22b64-ab0a-4376-dbcc-11b20c32893f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZFDeH49oimS",
        "colab_type": "code",
        "outputId": "582d926b-48b2-4f68-b636-1054ff354081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "poses[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NNS',\n",
              " 'IN',\n",
              " 'NNS',\n",
              " 'VBP',\n",
              " 'VBN',\n",
              " 'IN',\n",
              " 'NNP',\n",
              " 'TO',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NNP',\n",
              " 'CC',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'NNS',\n",
              " 'IN',\n",
              " 'DT',\n",
              " 'NN',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrY_JvunolXp",
        "colab_type": "code",
        "outputId": "1279ae34-57c7-4850-ef03-add6f6e7c599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "labels[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-geo',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-geo',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-gpe',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYI2fSwfopke",
        "colab_type": "text"
      },
      "source": [
        "### Target Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83PuX8Aon-Y",
        "colab_type": "code",
        "outputId": "919229f2-ee59-4767-e1a8-f65e136da581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "tags_vals = list(set(df[\"Tag\"].values)) + ['X', '[CLS]', '[SEP]']\n",
        "tags_vals"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-geo',\n",
              " 'B-eve',\n",
              " 'I-geo',\n",
              " 'B-tim',\n",
              " 'I-gpe',\n",
              " 'I-org',\n",
              " 'B-org',\n",
              " 'I-tim',\n",
              " 'B-gpe',\n",
              " 'I-per',\n",
              " 'B-art',\n",
              " 'I-eve',\n",
              " 'I-nat',\n",
              " 'I-art',\n",
              " 'B-nat',\n",
              " 'B-per',\n",
              " 'O',\n",
              " 'X',\n",
              " '[CLS]',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRkMO2W5pEqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2idx={'B-art': 14,\n",
        " 'B-eve': 16,\n",
        " 'B-geo': 0,\n",
        " 'B-gpe': 13,\n",
        " 'B-nat': 12,\n",
        " 'B-org': 10,\n",
        " 'B-per': 4,\n",
        " 'B-tim': 2,\n",
        " 'I-art': 5,\n",
        " 'I-eve': 7,\n",
        " 'I-geo': 15,\n",
        " 'I-gpe': 8,\n",
        " 'I-nat': 11,\n",
        " 'I-org': 3,\n",
        " 'I-per': 6,\n",
        " 'I-tim': 1,\n",
        " 'X':17,\n",
        " 'O': 9,\n",
        " '[CLS]':18,\n",
        " '[SEP]':19}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDttXbjWpQTH",
        "colab_type": "code",
        "outputId": "ad6258e8-d548-47a6-b24c-23eb48cacd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}\n",
        "tag2name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'B-geo',\n",
              " 1: 'I-tim',\n",
              " 2: 'B-tim',\n",
              " 3: 'I-org',\n",
              " 4: 'B-per',\n",
              " 5: 'I-art',\n",
              " 6: 'I-per',\n",
              " 7: 'I-eve',\n",
              " 8: 'I-gpe',\n",
              " 9: 'O',\n",
              " 10: 'B-org',\n",
              " 11: 'I-nat',\n",
              " 12: 'B-nat',\n",
              " 13: 'B-gpe',\n",
              " 14: 'B-art',\n",
              " 15: 'I-geo',\n",
              " 16: 'B-eve',\n",
              " 17: 'X',\n",
              " 18: '[CLS]',\n",
              " 19: '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeViPQxVpnXh",
        "colab_type": "text"
      },
      "source": [
        "### Creating Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIXYCFk_p5au",
        "colab_type": "code",
        "outputId": "2e99cd0c-7a7f-4c5f-deca-b366b9ac5210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 50.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.18)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=95b8131a44628ac712bdf1e70829a35270fb984de695b5aa3fe1105bc74f75c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, regex, sacremoses, transformers\n",
            "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkF0RHnap4Vu",
        "colab_type": "code",
        "outputId": "d7173657-1f52-485c-b7dd-3e3391bf7568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, \n",
        "                          BertConfig, BertForTokenClassification, BertTokenizer)\n",
        "from transformers import AdamW, WarmupLinearSchedule"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGZD5IA9pVCO",
        "colab_type": "code",
        "outputId": "df72cb55-37a8-4e12-c88b-5edf949b3427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForTokenClassification, BertTokenizer),\n",
        "}\n",
        "\n",
        "model_name = \"bert\"\n",
        "pretrained_model_name = \"bert-base-cased\"\n",
        "n_classes = len(tags_vals)\n",
        "\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_name]\n",
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_model_name, do_lower_case=False)\n",
        "model = model_class.from_pretrained(pretrained_model_name, num_labels=n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 158361.54B/s]\n",
            "100%|██████████| 213450/213450 [00:00<00:00, 977369.30B/s]\n",
            "100%|██████████| 435779157/435779157 [00:14<00:00, 30708045.68B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5THjunuXppX0",
        "colab_type": "code",
        "outputId": "aea79e61-d84f-4555-bbea-9791180beca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "tokenized_texts = []\n",
        "word_piece_labels = []\n",
        "i_inc = 0\n",
        "for word_list,label in (zip(sentences,labels)):\n",
        "    temp_lable = []\n",
        "    temp_token = []\n",
        "    \n",
        "    # Add [CLS] at the front \n",
        "    temp_lable.append('[CLS]')\n",
        "    temp_token.append('[CLS]')\n",
        "    \n",
        "    for word,lab in zip(word_list,label):\n",
        "        token_list = tokenizer.tokenize(word)\n",
        "        for m,token in enumerate(token_list):\n",
        "            temp_token.append(token)\n",
        "            if m==0:\n",
        "                temp_lable.append(lab)\n",
        "            else:\n",
        "                temp_lable.append('X')  \n",
        "                \n",
        "    # Add [SEP] at the end\n",
        "    temp_lable.append('[SEP]')\n",
        "    temp_token.append('[SEP]')\n",
        "    \n",
        "    tokenized_texts.append(temp_token)\n",
        "    word_piece_labels.append(temp_lable)\n",
        "    \n",
        "    if 5 > i_inc:\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
        "        print(\"texts:%s\"%(\" \".join(temp_token)))\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
        "        print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
        "    i_inc +=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.0,len:28\n",
            "texts:[CLS] Thousands of demons ##tra ##tors have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . [SEP]\n",
            "No.0,len:28\n",
            "lables:[CLS] O O O X X O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O [SEP]\n",
            "No.1,len:29\n",
            "texts:[CLS] Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an I ##A ##EA surveillance system begins functioning . [SEP]\n",
            "No.1,len:29\n",
            "lables:[CLS] B-gpe O O O O O O O O O O O O O O B-tim O O O B-org X X O O O O O [SEP]\n",
            "No.2,len:44\n",
            "texts:[CLS] He ##lic ##op ##ter guns ##hips Saturday pounded militant hide ##outs in the Or ##ak ##zai tribal region , where many Taliban militants are believed to have fled to avoid an earlier military offensive in nearby South W ##azi ##rist ##an . [SEP]\n",
            "No.2,len:44\n",
            "lables:[CLS] O X X X O X B-tim O O O X O O B-geo X X O O O O O B-org O O O O O O O O O O O O O O B-geo I-geo X X X O [SEP]\n",
            "No.3,len:16\n",
            "texts:[CLS] They left after a tense hour - long stand ##off with riot police . [SEP]\n",
            "No.3,len:16\n",
            "lables:[CLS] O O O O O O X X O X O O O O [SEP]\n",
            "No.4,len:47\n",
            "texts:[CLS] U . N . relief coordinator Jan E ##gel ##and said Sunday , U . S . , Indonesian and Australian military helicopters are ferry ##ing out food and supplies to remote areas of western Ace ##h province that ground crews can not reach . [SEP]\n",
            "No.4,len:47\n",
            "lables:[CLS] B-geo X X X O O B-per I-per X X O B-tim O B-geo X X X O B-gpe O B-gpe O O O O X O O O O O O O O O B-geo X O O O O O O O O [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zve_SSvXrgYL",
        "colab_type": "code",
        "outputId": "cee45d9a-fd20-4668-ce3d-e12c32db024a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 50\n",
        "\n",
        "# Make text token into id\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[  101 26159  1104  8568  4487  5067  1138  9639  1194  1498  1106  5641\n",
            "  1103  1594  1107  5008  1105  4555  1103 10602  1104  1418  2830  1121\n",
            "  1115  1583   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvdw_Tkerqw4",
        "colab_type": "code",
        "outputId": "771d3cd1-2d59-46e8-c781-ae2a4ded5175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Make label into id, pad with \"O\" meaning others\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
        "                     maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "print(tags[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18  9  9  9 17 17  9  9  9  0  9  9  9  9  9  0  9  9  9  9  9 13  9  9\n",
            "  9  9  9 19  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
            "  9  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD0LSUq4rxSA",
        "colab_type": "code",
        "outputId": "bd21236b-724c-47d9-e59e-f882763d8dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        }
      },
      "source": [
        "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "attention_masks[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glGB6AOvsCIr",
        "colab_type": "code",
        "outputId": "d0f82a5d-5e71-404d-d751-90ba31383b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Since only one sentence, all the segment set to 0\n",
        "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "print(segment_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLS06kRysK_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "tr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks, tr_segs, val_segs = train_test_split(input_ids, tags,attention_masks,segment_ids, \n",
        "                                                            random_state=0, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEb0gmTLsX84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs, dtype=torch.long)\n",
        "val_inputs = torch.tensor(val_inputs, dtype=torch.long)\n",
        "tr_tags = torch.tensor(tr_tags, dtype=torch.long)\n",
        "val_tags = torch.tensor(val_tags, dtype=torch.long)\n",
        "tr_masks = torch.tensor(tr_masks, dtype=torch.long)\n",
        "val_masks = torch.tensor(val_masks, dtype=torch.long)\n",
        "tr_segs = torch.tensor(tr_segs, dtype=torch.long)\n",
        "val_segs = torch.tensor(val_segs, dtype=torch.long)\n",
        "\n",
        "batch_num = 10\n",
        "\n",
        "# Only set token embedding, attention embedding, no segment embedding\n",
        "train_data = data.TensorDataset(tr_inputs, tr_masks, tr_segs, tr_tags)\n",
        "train_sampler = data.RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_num, drop_last=True)\n",
        "\n",
        "valid_data = data.TensorDataset(val_inputs, val_masks, val_segs, val_tags)\n",
        "valid_sampler = data.SequentialSampler(valid_data)\n",
        "valid_dataloader = data.DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QejbViYCtDvW",
        "colab_type": "text"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrVv_vais_ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "epochs = 1\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs\n",
        "# Fine tune model all layer parameters\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "      'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QaDAV9Itk36",
        "colab_type": "code",
        "outputId": "17e29372-42e0-47cd-e102-65ac17b41b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from tqdm import tqdm,trange\n",
        "\n",
        "n_gpu=1\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_segs, b_labels = batch\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=b_segs,\n",
        "        attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss, scores = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 33571\n",
            "  Batch size = 10\n",
            "  Num steps = 3358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 1/1 [05:16<00:00, 316.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.11722836958115163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgOHcFIFxykL",
        "colab_type": "text"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeXanpDNuMFz",
        "colab_type": "code",
        "outputId": "b4298652-720b-43ea-c71c-c2381d40d469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, input_mask, input_segs, label_ids = batch\n",
        "    \n",
        "#     if step > 2:\n",
        "#         break\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None,\n",
        "        attention_mask=input_mask,)\n",
        "        # For eval mode, the first result of outputs is logits\n",
        "        logits = outputs[0] \n",
        "    \n",
        "    # Get NER predict result\n",
        "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    \n",
        "    # Get NER true result\n",
        "    label_ids = label_ids.to('cpu').numpy()\n",
        "    \n",
        "    # Only predict the real word, mark=0, will not calculate\n",
        "    input_mask = input_mask.to('cpu').numpy()\n",
        "    \n",
        "    # Compare the valuable predict result\n",
        "    for i,mask in enumerate(input_mask):\n",
        "        # Real one\n",
        "        temp_1 = []\n",
        "        # Predict one\n",
        "        temp_2 = []\n",
        "        for j, m in enumerate(mask):\n",
        "            # Mark=0, meaning its a pad word, dont compare\n",
        "            if m:\n",
        "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                    temp_1.append(tag2name[label_ids[i][j]])\n",
        "                    temp_2.append(tag2name[logits[i][j]])\n",
        "            else:\n",
        "                break\n",
        "        y_true.append(temp_1)\n",
        "        y_pred.append(temp_2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =14388\n",
            "  Batch size = 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUSHptk_uvPQ",
        "colab_type": "code",
        "outputId": "59081043-6a72-4b95-9c10-dd8dfce7cb0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "actuals = [item for sl in y_true for item in sl]\n",
        "preds = [item for sl in y_pred for item in sl]\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"f1 socre: %f\"%(metrics.f1_score(actuals, preds, average=\"macro\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 socre: 0.527142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA5Se8eDuxtQ",
        "colab_type": "code",
        "outputId": "455de217-7a95-4b6f-f794-a69707ef4603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Accuracy score: %f\"%(metrics.accuracy_score(actuals, preds)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.969593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oxCOngku47k",
        "colab_type": "code",
        "outputId": "cc0f001c-9294-485e-a37b-e50159590891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "print(metrics.classification_report(actuals, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00       134\n",
            "       B-eve       0.59      0.39      0.47        98\n",
            "       B-geo       0.86      0.90      0.88     11313\n",
            "       B-gpe       0.96      0.93      0.95      4802\n",
            "       B-nat       0.45      0.18      0.26        71\n",
            "       B-org       0.79      0.72      0.75      5997\n",
            "       B-per       0.83      0.86      0.84      5120\n",
            "       B-tim       0.93      0.87      0.90      6242\n",
            "       I-art       0.00      0.00      0.00       100\n",
            "       I-eve       0.40      0.11      0.18        88\n",
            "       I-geo       0.86      0.72      0.78      2287\n",
            "       I-gpe       0.96      0.43      0.60        60\n",
            "       I-nat       0.00      0.00      0.00        21\n",
            "       I-org       0.83      0.76      0.79      5095\n",
            "       I-per       0.81      0.94      0.87      5160\n",
            "       I-tim       0.89      0.65      0.75      1996\n",
            "           O       0.99      0.99      0.99    264402\n",
            "           X       0.00      0.00      0.00         0\n",
            "       [CLS]       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97    312986\n",
            "   macro avg       0.59      0.50      0.53    312986\n",
            "weighted avg       0.97      0.97      0.97    312986\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}