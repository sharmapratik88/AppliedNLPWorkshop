{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_TextClassification_Embeddings",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhOfa2HjhvxS",
        "colab_type": "text"
      },
      "source": [
        "### Deep Learning Models using Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIN3RnUchnQU",
        "colab_type": "code",
        "outputId": "10835481-f6c4-4758-c277-dbb54c9f6483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du_4rcfYh3SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCJCSrrtkabn",
        "colab_type": "code",
        "outputId": "eaba5ea9-4cfb-4bcc-ed9b-cc7cf9a0a87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, GRU\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9exV10lfjIwW",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59crBIw7jCN_",
        "colab_type": "code",
        "outputId": "04333803-d1ea-446f-c5aa-73b3b606b42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "data_path = \"/content/drive/My Drive/Datahack NLP Workshop/Disaster/\"\n",
        "df = pd.read_csv(data_path + \"socialmedia_disaster_tweets.csv\", encoding='iso-8859-1')\n",
        "df = df[[\"choose_one\", \"text\"]]\n",
        "df.columns = [\"label\", \"text\"]\n",
        "df = df[df[\"label\"].isin([\"Relevant\", \"Not Relevant\"])].reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Relevant</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Relevant</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Relevant</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Relevant</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Relevant</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text\n",
              "0  Relevant                 Just happened a terrible car crash\n",
              "1  Relevant  Our Deeds are the Reason of this #earthquake M...\n",
              "2  Relevant  Heard about #earthquake is different cities, s...\n",
              "3  Relevant  there is a forest fire at spot pond, geese are...\n",
              "4  Relevant             Forest fire near La Ronge Sask. Canada"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGt8DKnAkp67",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM7ErehujGzY",
        "colab_type": "code",
        "outputId": "6ec8a0ae-cb3d-43fc-a619-b57cfc754059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## some config values \n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a question to use\n",
        "\n",
        "## fill up the missing values\n",
        "X = df[\"text\"].astype(str).fillna(\"_na_\").values\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features, oov_token='<UNK>') #out of vocabulary token\n",
        "tokenizer.fit_on_texts(list(X)) #words to ids\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "## Pad the sentences \n",
        "X = pad_sequences(X, maxlen=maxlen)\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10860, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jspz7kAlI1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = {\"Not Relevant\":0, \"Relevant\":1}\n",
        "y = (df[\"label\"].map(label_map)).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRFykFzXx6jn",
        "colab_type": "text"
      },
      "source": [
        "### GPU Availability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMc_P3LHyHNh",
        "colab_type": "text"
      },
      "source": [
        "Setting up GPU Colab: https://colab.research.google.com/notebooks/gpu.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coAYY78Xml0m",
        "colab_type": "code",
        "outputId": "463bfc25-1e22-40fe-9512-2bd58f17ba9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFINFcYLyLo7",
        "colab_type": "text"
      },
      "source": [
        "### Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5-rTxTClO7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(X, y, val_X, val_y, batch_size=128, n_epochs=1):\n",
        "  inp = Input(shape=(maxlen,))\n",
        "  x = Embedding(max_features, embed_size)(inp)\n",
        "  x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "  x = GlobalMaxPool1D()(x)\n",
        "  x = Dense(16, activation=\"relu\")(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  x = Dense(1, activation=\"sigmoid\")(x)\n",
        "  model = Model(inputs=inp, outputs=x)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X, y, batch_size=batch_size, epochs=n_epochs, validation_data=(val_X, val_y))\n",
        "\n",
        "  pred_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "\n",
        "  return model, pred_val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KEdCz67leaq",
        "colab_type": "code",
        "outputId": "2f0288b8-092a-4d33-8168-8bb2a7b9059a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
        "cv_preds = np.zeros(X.shape[0])\n",
        "for dev_index, val_index in kf.split(X):\n",
        "    dev_X, val_X = X[dev_index,:], X[val_index,:]\n",
        "    dev_y, val_y = y[dev_index], y[val_index]\n",
        "\n",
        "    model, preds_val = run_model(dev_X, dev_y, val_X, val_y)\n",
        "    cv_preds[val_index] = preds_val.ravel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "8688/8688 [==============================] - 11s 1ms/sample - loss: 0.5727 - acc: 0.7064 - val_loss: 0.4237 - val_acc: 0.8117\n",
            "2172/2172 [==============================] - 3s 2ms/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "8688/8688 [==============================] - 2s 208us/sample - loss: 0.5852 - acc: 0.6981 - val_loss: 0.4483 - val_acc: 0.8025\n",
            "2172/2172 [==============================] - 0s 52us/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "8688/8688 [==============================] - 2s 213us/sample - loss: 0.5962 - acc: 0.6937 - val_loss: 0.4655 - val_acc: 0.7901\n",
            "2172/2172 [==============================] - 0s 58us/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "8688/8688 [==============================] - 2s 220us/sample - loss: 0.5879 - acc: 0.6960 - val_loss: 0.4333 - val_acc: 0.8034\n",
            "2172/2172 [==============================] - 0s 60us/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "8688/8688 [==============================] - 2s 223us/sample - loss: 0.5982 - acc: 0.6792 - val_loss: 0.4316 - val_acc: 0.8108\n",
            "2172/2172 [==============================] - 0s 76us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWP09KrvlmG6",
        "colab_type": "code",
        "outputId": "4e2efdd9-da2f-4242-d6b0-728a5de59ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.roc_auc_score(y, cv_preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8643978726924125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIgBh1Y70OSs",
        "colab_type": "code",
        "outputId": "a7b08f87-5463-4408-9bbb-d5cd577ef43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "print(metrics.classification_report(y, (cv_preds>0.5)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.84      6187\n",
            "           1       0.81      0.71      0.76      4673\n",
            "\n",
            "    accuracy                           0.80     10860\n",
            "   macro avg       0.80      0.79      0.80     10860\n",
            "weighted avg       0.80      0.80      0.80     10860\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M_mRh1S2aWl",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO2WW1M40Qxi",
        "colab_type": "code",
        "outputId": "635f4642-5c08-4763-dcfb-ce76fe6d63b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "EMBEDDING_FILE = \"/content/drive/My Drive/Datahack NLP Workshop/Disaster/w2vec.txt\" \n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8PaumIB22TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(X, y, val_X, val_y, batch_size=128, n_epochs=10):\n",
        "  inp = Input(shape=(maxlen,))\n",
        "  x = Embedding(embedding_matrix.shape[0], embed_size, weights=[embedding_matrix])(inp) #https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "  x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "  x = GlobalMaxPool1D()(x)\n",
        "  x = Dense(16, activation=\"relu\")(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  x = Dense(1, activation=\"sigmoid\")(x)\n",
        "  model = Model(inputs=inp, outputs=x)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X, y, batch_size=batch_size, epochs=n_epochs, validation_data=(val_X, val_y))\n",
        "\n",
        "  pred_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "\n",
        "  return model, pred_val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcCvFerQ3A7I",
        "colab_type": "code",
        "outputId": "1a626791-7cbf-43ae-8c03-41759324bbdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
        "cv_preds = np.zeros(X.shape[0])\n",
        "for dev_index, val_index in kf.split(X):\n",
        "    dev_X, val_X = X[dev_index,:], X[val_index,:]\n",
        "    dev_y, val_y = y[dev_index], y[val_index]\n",
        "\n",
        "    model, preds_val = run_model(dev_X, dev_y, val_X, val_y)\n",
        "    cv_preds[val_index] = preds_val.ravel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8688 samples, validate on 2172 samples\n",
            "Epoch 1/10\n",
            "8688/8688 [==============================] - 2s 227us/sample - loss: 0.5211 - acc: 0.7467 - val_loss: 0.4332 - val_acc: 0.7983\n",
            "Epoch 2/10\n",
            "8688/8688 [==============================] - 1s 157us/sample - loss: 0.3747 - acc: 0.8438 - val_loss: 0.4080 - val_acc: 0.8200\n",
            "Epoch 3/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.2467 - acc: 0.9045 - val_loss: 0.5048 - val_acc: 0.7891\n",
            "Epoch 4/10\n",
            "8688/8688 [==============================] - 1s 160us/sample - loss: 0.1137 - acc: 0.9611 - val_loss: 0.6509 - val_acc: 0.7726\n",
            "Epoch 5/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0490 - acc: 0.9852 - val_loss: 0.8703 - val_acc: 0.7587\n",
            "Epoch 6/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.0313 - acc: 0.9910 - val_loss: 0.9675 - val_acc: 0.7311\n",
            "Epoch 7/10\n",
            "8688/8688 [==============================] - 1s 163us/sample - loss: 0.0235 - acc: 0.9931 - val_loss: 0.9171 - val_acc: 0.7601\n",
            "Epoch 8/10\n",
            "8688/8688 [==============================] - 1s 157us/sample - loss: 0.0178 - acc: 0.9945 - val_loss: 1.0985 - val_acc: 0.7353\n",
            "Epoch 9/10\n",
            "8688/8688 [==============================] - 1s 160us/sample - loss: 0.0165 - acc: 0.9941 - val_loss: 1.0000 - val_acc: 0.7601\n",
            "Epoch 10/10\n",
            "8688/8688 [==============================] - 1s 155us/sample - loss: 0.0143 - acc: 0.9952 - val_loss: 1.0775 - val_acc: 0.7551\n",
            "2172/2172 [==============================] - 0s 80us/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "Epoch 1/10\n",
            "8688/8688 [==============================] - 2s 231us/sample - loss: 0.5115 - acc: 0.7570 - val_loss: 0.4473 - val_acc: 0.7951\n",
            "Epoch 2/10\n",
            "8688/8688 [==============================] - 1s 163us/sample - loss: 0.3662 - acc: 0.8447 - val_loss: 0.4335 - val_acc: 0.8099\n",
            "Epoch 3/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.2332 - acc: 0.9108 - val_loss: 0.5126 - val_acc: 0.7776\n",
            "Epoch 4/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.1078 - acc: 0.9652 - val_loss: 0.6684 - val_acc: 0.7546\n",
            "Epoch 5/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0478 - acc: 0.9865 - val_loss: 0.8104 - val_acc: 0.7661\n",
            "Epoch 6/10\n",
            "8688/8688 [==============================] - 1s 157us/sample - loss: 0.0301 - acc: 0.9922 - val_loss: 0.8617 - val_acc: 0.7610\n",
            "Epoch 7/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.0220 - acc: 0.9948 - val_loss: 0.9835 - val_acc: 0.7440\n",
            "Epoch 8/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0173 - acc: 0.9946 - val_loss: 0.9970 - val_acc: 0.7587\n",
            "Epoch 9/10\n",
            "8688/8688 [==============================] - 1s 155us/sample - loss: 0.0159 - acc: 0.9955 - val_loss: 1.1114 - val_acc: 0.7353\n",
            "Epoch 10/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0143 - acc: 0.9949 - val_loss: 1.1413 - val_acc: 0.7413\n",
            "2172/2172 [==============================] - 0s 87us/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "Epoch 1/10\n",
            "8688/8688 [==============================] - 2s 241us/sample - loss: 0.5632 - acc: 0.7293 - val_loss: 0.4959 - val_acc: 0.7891\n",
            "Epoch 2/10\n",
            "8688/8688 [==============================] - 1s 162us/sample - loss: 0.4110 - acc: 0.8313 - val_loss: 0.4476 - val_acc: 0.8066\n",
            "Epoch 3/10\n",
            "8688/8688 [==============================] - 1s 154us/sample - loss: 0.2652 - acc: 0.9047 - val_loss: 0.5043 - val_acc: 0.8016\n",
            "Epoch 4/10\n",
            "8688/8688 [==============================] - 1s 156us/sample - loss: 0.1347 - acc: 0.9622 - val_loss: 0.6384 - val_acc: 0.7652\n",
            "Epoch 5/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0781 - acc: 0.9841 - val_loss: 0.7905 - val_acc: 0.7716\n",
            "Epoch 6/10\n",
            "8688/8688 [==============================] - 1s 163us/sample - loss: 0.0581 - acc: 0.9896 - val_loss: 0.9544 - val_acc: 0.7610\n",
            "Epoch 7/10\n",
            "8688/8688 [==============================] - 1s 161us/sample - loss: 0.0475 - acc: 0.9931 - val_loss: 0.9716 - val_acc: 0.7454\n",
            "Epoch 8/10\n",
            "8688/8688 [==============================] - 1s 161us/sample - loss: 0.0404 - acc: 0.9946 - val_loss: 1.0823 - val_acc: 0.7440\n",
            "Epoch 9/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0372 - acc: 0.9959 - val_loss: 1.1526 - val_acc: 0.7325\n",
            "Epoch 10/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.0377 - acc: 0.9957 - val_loss: 1.2928 - val_acc: 0.7376\n",
            "2172/2172 [==============================] - 0s 100us/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "Epoch 1/10\n",
            "8688/8688 [==============================] - 2s 250us/sample - loss: 0.5333 - acc: 0.7400 - val_loss: 0.4533 - val_acc: 0.7933\n",
            "Epoch 2/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.3757 - acc: 0.8393 - val_loss: 0.4238 - val_acc: 0.8126\n",
            "Epoch 3/10\n",
            "8688/8688 [==============================] - 1s 154us/sample - loss: 0.2436 - acc: 0.9087 - val_loss: 0.4619 - val_acc: 0.8071\n",
            "Epoch 4/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.1195 - acc: 0.9605 - val_loss: 0.6053 - val_acc: 0.7799\n",
            "Epoch 5/10\n",
            "8688/8688 [==============================] - 1s 160us/sample - loss: 0.0551 - acc: 0.9835 - val_loss: 0.7190 - val_acc: 0.7808\n",
            "Epoch 6/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0323 - acc: 0.9908 - val_loss: 0.7810 - val_acc: 0.7762\n",
            "Epoch 7/10\n",
            "8688/8688 [==============================] - 1s 164us/sample - loss: 0.0206 - acc: 0.9939 - val_loss: 0.9295 - val_acc: 0.7541\n",
            "Epoch 8/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0166 - acc: 0.9944 - val_loss: 0.9107 - val_acc: 0.7574\n",
            "Epoch 9/10\n",
            "8688/8688 [==============================] - 1s 160us/sample - loss: 0.0140 - acc: 0.9944 - val_loss: 1.0020 - val_acc: 0.7564\n",
            "Epoch 10/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0137 - acc: 0.9957 - val_loss: 1.0170 - val_acc: 0.7551\n",
            "2172/2172 [==============================] - 0s 109us/sample\n",
            "Train on 8688 samples, validate on 2172 samples\n",
            "Epoch 1/10\n",
            "8688/8688 [==============================] - 2s 251us/sample - loss: 0.5296 - acc: 0.7431 - val_loss: 0.4415 - val_acc: 0.8117\n",
            "Epoch 2/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.3814 - acc: 0.8383 - val_loss: 0.4122 - val_acc: 0.8273\n",
            "Epoch 3/10\n",
            "8688/8688 [==============================] - 1s 157us/sample - loss: 0.2544 - acc: 0.9048 - val_loss: 0.4659 - val_acc: 0.8034\n",
            "Epoch 4/10\n",
            "8688/8688 [==============================] - 1s 157us/sample - loss: 0.1229 - acc: 0.9580 - val_loss: 0.5742 - val_acc: 0.7827\n",
            "Epoch 5/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.0514 - acc: 0.9842 - val_loss: 0.7604 - val_acc: 0.7643\n",
            "Epoch 6/10\n",
            "8688/8688 [==============================] - 1s 156us/sample - loss: 0.0281 - acc: 0.9932 - val_loss: 0.9690 - val_acc: 0.7403\n",
            "Epoch 7/10\n",
            "8688/8688 [==============================] - 1s 162us/sample - loss: 0.0189 - acc: 0.9953 - val_loss: 0.8691 - val_acc: 0.7808\n",
            "Epoch 8/10\n",
            "8688/8688 [==============================] - 1s 159us/sample - loss: 0.0192 - acc: 0.9940 - val_loss: 1.0547 - val_acc: 0.7555\n",
            "Epoch 9/10\n",
            "8688/8688 [==============================] - 1s 162us/sample - loss: 0.0148 - acc: 0.9952 - val_loss: 0.9842 - val_acc: 0.7703\n",
            "Epoch 10/10\n",
            "8688/8688 [==============================] - 1s 158us/sample - loss: 0.0133 - acc: 0.9960 - val_loss: 1.0503 - val_acc: 0.7675\n",
            "2172/2172 [==============================] - 0s 109us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJXehSmv3D1b",
        "colab_type": "code",
        "outputId": "8fbfca69-5833-41d9-9a6b-0be0b592f4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.roc_auc_score(y, cv_preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8143921674195125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpSkZOLw3lYY",
        "colab_type": "code",
        "outputId": "b53845dd-0f3d-42d9-c016-8f072b9d95b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "print(metrics.classification_report(y, (cv_preds>0.5)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79      6187\n",
            "           1       0.73      0.68      0.70      4673\n",
            "\n",
            "    accuracy                           0.75     10860\n",
            "   macro avg       0.75      0.74      0.74     10860\n",
            "weighted avg       0.75      0.75      0.75     10860\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}